{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26b97f9-6618-460e-9ec6-4ada623427e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель размещена на: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "#### не помещается\n",
    "model_name = \"Vikhrmodels/Vikhr-Llama-3.2-1B-Instruct\" \n",
    "\n",
    "# Загрузка токенайзера\n",
    "tokenizer_llm = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Загрузка модели и помещение на GPU\n",
    "model_llm = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "\n",
    "\n",
    "def empty_gpu_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "\n",
    "# Проверка устройства\n",
    "print(f\"Модель размещена на: {next(model_llm.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97354371-638e-4e5c-b7f5-00d3bb14625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompt, context, model, tokenizer, tokens_number = 512, temp = 0.3, top_k = 50, top_p = 0.95):\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": context}, \n",
    "                                               {\"role\": \"user\", \"content\": prompt}],\n",
    "                                              truncation=True,\n",
    "                                          add_generation_prompt=False, padding=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_new_tokens=tokens_number,\n",
    "                do_sample=True,\n",
    "                temperature=temp,\n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]\n",
    "\n",
    "    ans = decoded_output.split('<|start_header_id|>assistant<|end_header_id|>')\n",
    "    answer = ans[-1].replace('<|eot_id|>', '').strip()\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f267ae8-738d-49c8-a426-6292e759692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kolya/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers sentencepiece\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model_bert = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# model.cuda()  # uncomment it if you have a GPU\n",
    "\n",
    "def embed_bert(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]  # вектор токена [CLS], который является агрегированной информацией о всём тексте\n",
    "    #embeddings = model_output.pooler_output\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "# print(embed_bert_cls('привет мир', model, tokenizer))\n",
    "# (312,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b5c896-de31-4d0c-abd3-2e64b9ac4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_distance(e1, e2):\n",
    "    return 1 - dot(e1, e2)/np.linalg.norm(e1)/np.linalg.norm(e2)\n",
    "\n",
    "class Retrieval:\n",
    "    def __init__(self, chunks, model, tokenizer):\n",
    "        if isinstance(chunks, pd.DataFrame):\n",
    "            self.chunks = list(chunks[\"chunks\"])\n",
    "        elif isinstance(chunks, list):\n",
    "            self.chunks = chunks\n",
    "        else:\n",
    "            raise TypeError('чанки должны быть или списком или датафреймом')\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.chunk_vecs = []\n",
    "        for chunk in self.chunks:\n",
    "            self.chunk_vecs.append(list(embed_bert(chunk, model, tokenizer)))\n",
    "        self.chunk_vecs = np.array(self.chunk_vecs)\n",
    "\n",
    "    def get_chunks(self):\n",
    "        return self.chunks\n",
    "    \n",
    "    def find_context(self, question):\n",
    "        q_emb = embed_bert(question, self.model, self.tokenizer)\n",
    "        min_ind = 0\n",
    "        distances = []\n",
    "        for i in range(len(self.chunks)):\n",
    "            distances.append(cos_distance(q_emb, self.chunk_vecs[i]))\n",
    "        min_ind = np.argmin(distances)\n",
    "\n",
    "        return self.chunks[min_ind], distances[min_ind], min_ind, distances\n",
    "\n",
    "    def find_top_k_context(self, question, k):\n",
    "        q_emb = embed_bert(question, self.model, self.tokenizer)\n",
    "        min_ind = 0\n",
    "        distances = []\n",
    "        for i in range(len(self.chunks)):\n",
    "            distances.append((cos_distance(q_emb, self.chunk_vecs[i]), i))\n",
    "\n",
    "        distances.sort(reverse = False, key = lambda x: x[0])\n",
    "        distances = distances[:k]\n",
    "        indexes = list(map(lambda x: x[1], distances))\n",
    "        dist = list(map(lambda x: x[0], distances))\n",
    "        return indexes, dist\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e1424a1-9a98-4ea2-8b64-8636fa27a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    def __init__(self, retr: Retrieval, model, tokenizer):\n",
    "        self.retr = retr\n",
    "        self.model_llm = model\n",
    "        self.tokenizer_llm = tokenizer\n",
    "\n",
    "    def _get_answer(self, prompt: str, context: str, model, tokenizer, tokens_number = 512, temp = 0.3, top_k = 50, top_p = 0.95):\n",
    "        \n",
    "        input_ids = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": context}, \n",
    "                                                   {\"role\": \"user\", \"content\": prompt}],\n",
    "                                                  truncation=True,\n",
    "                                              add_generation_prompt=False, padding=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            outputs = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    max_new_tokens=tokens_number,\n",
    "                    do_sample=True,\n",
    "                    temperature=temp,\n",
    "                    top_k=top_k,\n",
    "                    top_p=top_p,\n",
    "                    pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "    \n",
    "        decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]\n",
    "    \n",
    "        ans = decoded_output.split('<|start_header_id|>assistant<|end_header_id|>')\n",
    "        answer = ans[-1].replace('<|eot_id|>', '').strip()\n",
    "        return answer\n",
    "    \n",
    "    def answer(self, prompt: str, temp=0.3):\n",
    "        indexes = self.retr.find_top_k_context(prompt,3)[0]\n",
    "        context = ''\n",
    "        for ind in indexes:\n",
    "            context+=self.retr.chunks[ind]\n",
    "            context+='\\n\\n'\n",
    "            \n",
    "        return self._get_answer(prompt, context, self.model_llm, self.tokenizer_llm, temp=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64af0e6a-b2e5-42cb-8678-d68f64431c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('chunks.csv')\n",
    "retr = Retrieval(df, model_bert, tokenizer_bert)\n",
    "rag = RAG(retr, model_llm, tokenizer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7efd7d-f3e0-4118-80e8-746024a90682",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_answers = []\n",
    "for i in range(len(df)):\n",
    "    real_answers.append(get_answer(df.loc[i, \"questions\"], df.loc[i, \"chunks\"], model_llm, tokenizer_llm, temp=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5dff8bd-547f-466a-9000-0dfff37431e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_answers = []\n",
    "for i in range(len(df)):\n",
    "    hypothesis = rag.answer(df.questions.loc[i], temp=0.1)\n",
    "    rag_answers.append(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6824bb1b-2d70-4d4d-9abb-d9aab8d89041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Контактные данные комендантов общежитий, указанные в вашем вопросе, следующий:\n",
      "\n",
      "- Общежитие №2: Комендант: Журкова Наталья Николаевна Завхоз: Синичкина Светлана Ивановна\n",
      "- Общежитие №5: Комендант: Новожилова Валентина Михайловна\n",
      "\n",
      "Общежитие №10 не указано в вашем запросе, поэтому я не могу предоставить информацию о коменданте этого общежития.\n"
     ]
    }
   ],
   "source": [
    "print(rag_answers[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a99d82e-bc9e-4344-8778-fc9e0bcb95a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Контактные данные комендантов общежитий по указанным адресам:\n",
      "\n",
      "- **Общежитие №2**:\n",
      "  - Комендант: **Наталья Николаевна Журкова**\n",
      "  - Телефон: +7-495-542-73-89\n",
      "\n",
      "- **Общежитие №5**:\n",
      "  - Комендант: **Валентина Михайловна Новожилова**\n",
      "  - Телефон: +7-499-367-78-18\n"
     ]
    }
   ],
   "source": [
    "print(real_answers[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22782eb0-889e-43c0-a39d-87adfa028e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оценка LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "643a42f9-adc2-4573-b1ed-fa21a45b2c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4503223307775391\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Пример для вычисления ROUGE\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2'])\n",
    "\n",
    "rouges = []\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    hypothesis = rag_answers[i]\n",
    "    reference = real_answers[i]\n",
    "    rouges.append(scorer.score(reference, hypothesis)['rouge1'].fmeasure)\n",
    "\n",
    "print(np.mean(rouges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "376539cf-b367-47dd-b0d9-a4abdb4d8025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/kolya/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "/home/kolya/venv/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 0.17341084379625854\n",
      "Average METEOR score: 0.3275126423446656\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Убедитесь, что у вас есть токенизация\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "# Токенизация\n",
    "rag_answers_tokenized = [nltk.word_tokenize(answer) for answer in rag_answers]\n",
    "df_answers_tokenized = [nltk.word_tokenize(answer) for answer in real_answers]\n",
    "\n",
    "# Вычисление BLEU и METEOR\n",
    "bleu_scores = []\n",
    "meteor_scores = []\n",
    "\n",
    "for rag_answer, df_answer in zip(rag_answers_tokenized, df_answers_tokenized):\n",
    "    # BLEU\n",
    "    bleu_score = sentence_bleu([df_answer], rag_answer)\n",
    "    bleu_scores.append(bleu_score)\n",
    "    \n",
    "    # METEOR\n",
    "    meteor_score_value = meteor_score([df_answer], rag_answer)\n",
    "    meteor_scores.append(meteor_score_value)\n",
    "\n",
    "# Средние метрики\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "average_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(f\"Average BLEU score: {average_bleu}\")\n",
    "print(f\"Average METEOR score: {average_meteor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85298d90-566a-453c-bd70-828b291a2542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d9dca2f-8e73-4b2f-9c67-f4b663498503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Сколько месяцев будет выплачиваться стипендия от VK и какой размер стипендии?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стипендия от VK выплачивается ежемесячно в течение 4 месяцев. Стоимость стипендии составляет 15 000 рублей в месяц.\n"
     ]
    }
   ],
   "source": [
    "ans = rag.answer(input())\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58291849-e0a5-4663-8265-82aba0822d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие образовательные профили подготовки реализует кафедра ФН-11 в рамках направления \"Математика и компьютерные науки\"?',\n",
       " 'Какие научные достижения были у профессора П.А. Зилова и Н.П. Слугинова?',\n",
       " 'Из каких частей состоит главный учебный корпус (ГУК) МГТУ и как они расположены?',\n",
       " 'Как устроено сообщение между подразделениями и нумерация аудиторий в ГУК МГТУ?',\n",
       " 'Когда был открыт учебно-лабораторный корпус (УЛК) МГТУ, и как проходило его строительство?',\n",
       " 'Сколько длится обучение по программе машинного обучения и какой конкурс на место?\\n\\n',\n",
       " 'Какие образовательные программы предлагает VK для студентов МГТУ им. Баумана?\\n\\n',\n",
       " 'Каковы шансы трудоустройства выпускников Центра в компанию VK после окончания обучения на должность высококлассного Web-, ML- или мобильного разработчика с опытом работы с высоконагруженными системами?\\n\\n',\n",
       " 'Какие возможности предоставляет проект для студентов?\\n\\n',\n",
       " 'Могут ли подать заявку на треки основной программы обучения студенты очно-заочной формы?\\n\\n',\n",
       " 'В чём разница между основной программой и семестровым курсом?\\n',\n",
       " 'Почему вы не зачисляете в проект первокурсников? \\n\\n',\n",
       " 'Могут ли преподаватели из Образовательного центра VK в МГТУ приглашать студентов на стажировку в свои компании?\\n\\n',\n",
       " 'Где проходят занятия в рамках гибридного формата?\\n',\n",
       " 'Где находятся мультимедийные залы и рабочие офисы сотрудников Образовательного центра VK в МГТУ?\\n\\n',\n",
       " 'В какие дни и в какое время проводятся занятия по основной программе?\\n\\n',\n",
       " 'Какие требования предъявляются к ноутбуку для разработки на IOS? ',\n",
       " 'Какие преимущества получают студенты, обучающиеся на ваших образовательных программах?\\n\\n',\n",
       " 'Какие возможности открываются для меня после поступления на курс?\\n\\n',\n",
       " 'Каковы условия участия в проекте для студентов МГТУ им. Н. Э. Баумана?\\n\\n',\n",
       " 'Каковы последствия невыполнения студентом необходимых требований для перехода на следующий семестр в вашем центре?\\n\\n',\n",
       " 'Какие навыки и знания необходимы студенту для успешного прохождения отбора в РАГ, если он интересуется программированием и самостоятельно учится решать задачи?\\n\\n',\n",
       " 'Вопрос: есть ли возможность посмотреть записи лекций для тех, кто не участвует в проекте?\\n',\n",
       " 'Как работает балльно-рейтинговая система и что нужно сделать для успешного перевода на следующий семестр? ',\n",
       " 'Какие последствия ждут студента, который не сдал хотя бы один из курсов?\\n',\n",
       " 'Каковы особенности обучения в Центре?\\n',\n",
       " 'Где лучше задавать вопросы преподавателю, если я пропустила занятие?  \\n\\n',\n",
       " 'Какие перспективы открываются перед студентами, которые успешно выполнят итоговый командный проект в последнем семестре?\\n\\n',\n",
       " 'Сколько часов в неделю занимает аудиторная работа и как много времени уходит на командные проекты?\\n\\n',\n",
       " 'Когда проходит набор на основную программу обучения?  \\n\\n',\n",
       " 'Какие языки программирования и парадигмы используются в первом семестре для решения практических заданий?\\n\\n',\n",
       " 'Какие этапы отбора необходимо пройти, чтобы поступить в РАГ?\\n\\n',\n",
       " 'Какие этапы отбора необходимо пройти, чтобы попасть в проект?\\n\\n',\n",
       " 'Как зарегистрироваться на отбор?\\n',\n",
       " 'Как проверить, что я зарегистрирован на проект, и где найти ссылку для участия в испытании?  \\n',\n",
       " 'Когда начинается обучение для тех, кто поступил на основную программу?\\n\\n',\n",
       " 'Вопрос: что даёт диплом об окончании курса, который я получу, если успешно завершу обучение?  \\n',\n",
       " 'Как проходит отбор на курсы и когда обычно начинается набор?',\n",
       " 'Сколько в среднем академических часов в неделю отводится на обучение по программам, если не учитывать время на выполнение домашних заданий?',\n",
       " 'Какие условия поступления на семестровые курсы и как происходит оценка знаний студентов?\\n',\n",
       " 'Сколько дополнительных баллов даёт сертификат об окончании курса при поступлении в магистратуру МГТУ?\\n\\n',\n",
       " 'Как зарегистрироваться на курсы РАГ, если я учусь в другом вузе?\\n',\n",
       " 'Какие требования предъявляются к студентам, чтобы получить стипендию от VK в 2023/2024 учебном году?\\n\\n',\n",
       " 'Сколько месяцев будет выплачиваться стипендия от VK и какой размер этой стипендии?\\n',\n",
       " 'Как часто пересматривается стипендия?\\n',\n",
       " 'От чего не зависит получение стипендии от компании VK?\\n\\n',\n",
       " 'Какие действия будут предприняты после того, как студент программы от VK выполнит все требования для получения стипендии?\\n',\n",
       " 'Где находится деканат ИУ и как связаться с деканом?\\n\\n',\n",
       " 'Где и в какие дни можно получить консультацию заведующего кафедрой ИУ5?\\n\\n',\n",
       " 'В какие дни и в какое время можно получить студенческую стипендию?\\n\\n',\n",
       " 'Где находится бухгалтерия и какой у неё график работы?\\n',\n",
       " 'Какой график работы у столовой на первом этаже главного здания и у буфета «Юг» в будние дни?\\n\\n',\n",
       " 'Какой график работы спортивного комплекса?\\n',\n",
       " 'Какой график работы у бюро пропусков в общежитии №11?\\n\\n',\n",
       " 'Какой график работы у отдела кадров студентов в УВЦ?\\n\\n',\n",
       " 'Сколько часов в день работает этот отдел?\\n',\n",
       " 'Где и в какое время можно получить социальную стипендию?\\n\\n',\n",
       " 'Где и когда студенты могут визировать анкету для оформления загранпаспорта?\\n\\n',\n",
       " 'Где и когда студентам нужно визировать анкету для оформления загранпаспорта?\\n\\n',\n",
       " 'Где и на каких условиях можно получить логин и пароль для доступа в интернет в общежитии?\\n',\n",
       " 'Где и на каких условиях можно получить интернет-карту для сотрудников и студентов?\\n\\n',\n",
       " 'Где и в какое время можно распечатать документы и чертежи в университете?\\n',\n",
       " 'Где в университете можно распечатать документы и получить интернет, и какие условия для этого нужно выполнить?\\n',\n",
       " 'Где в университете можно распечатать чертежи?\\n',\n",
       " 'Какой график работы у офиса «ЧЕРТЁЖ.ру»?\\n\\n',\n",
       " 'Каковы контактные данные комендантов общежитий, которые находятся по адресам: Госпитальная набережная, 4, строение 1а и Измайловский проспект, 73/2?\\n\\n',\n",
       " 'Какие контактные данные у общежития №2?\\n',\n",
       " 'Где можно узнать контактные данные коменданта общежития №10?\\n\\n',\n",
       " 'Где находится общежитие № 2 и как связаться с комендантом общежития № 5?\\n\\n',\n",
       " 'Где находится общежитие №5 и как связаться с комендантом?\\n\\n',\n",
       " 'Где находится общежитие № 10?\\n',\n",
       " 'Какой график работы у почтового отделения в Измайлово?\\n\\n',\n",
       " 'Какой график работы у военкомата в Измайлово и какие документы нужны для прохода туда?\\n',\n",
       " 'Какой график работы у военкомата на 5-й Парковой, 30а?\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384062c-5bb8-4da2-aaf6-b6d09e4a60f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
